# /lustre/fs12/portfolios/llmservice/users/abukharin/reasoning/alignment/NeMo-RL/examples/run_grpo_deepscaler.py \
# ++logger.wandb.name=rerun_8k_nemorl_math_qwen1.5b_lr_1e-6_temp_1_kl_0.001_grpo_bs_64_rollout_8_num_prompts_128 \
# ++logger.wandb_enabled=True \
# logger.wandb.project=deepscaler_replication \
# ++checkpointing.checkpoint_dir=/lustre/fs12/portfolios/llmservice/users/abukharin/reasoning/alignment/results/rerun_8k_nemorl_math_qwen1.5b_lr_1e-6_temp_1_kl_0.001_grpo_bs_64_rollout_8_num_prompts_128 \
# ++policy.model_name=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B \
# ++policy.make_sequence_length_divisible_by=8 \
# ++policy.generation.vllm_cfg.tensor_parallel_size=1 \
# ++cluster.num_nodes=1 \
# policy.dtensor_cfg.enabled=True \
# policy.dtensor_cfg.tensor_parallel_size=1 \
# policy.dtensor_cfg.sequence_parallel=True \
# policy.dtensor_cfg.activation_checkpointing=False \
# policy.dtensor_cfg.cpu_offload=False \
# ++cluster.gpus_per_node=8 \
# grpo.num_prompts_per_step=128 \
# grpo.num_generations_per_prompt=8 \
# grpo.val_period=10 \
# grpo.max_val_samples=64 \
# grpo.val_batch_size=64 \
# loss_fn.reference_policy_kl_penalty=0.001 \
# loss_fn.use_on_policy_kl_approximation=False \
# loss_fn.use_importance_sampling_correction=False \
# checkpointing.keep_top_k=10 \
# checkpointing.save_period=10 \
# policy.train_global_batch_size=64 \
# policy.train_micro_batch_size=1 \
# policy.generation_batch_size=32 \
# policy.logprob_batch_size=1 \
# policy.max_total_sequence_length=8192 \
# policy.optimizer.kwargs.lr=1e-6 \
# policy.optimizer.kwargs.weight_decay=0 \
# policy.generation.temperature=1 \
# policy.generation.vllm_cfg.tensor_parallel_size=1 \
# policy.generation.vllm_cfg.gpu_memory_utilization=0.6 \
# data.dataset_name=custom \
# ++data.train_data_path=/lustre/fs12/portfolios/llmservice/users/abukharin/reasoning/alignment/data/train_deepscaler.json \
# ++data.val_data_path=/lustre/fs12/portfolios/llmservice/users/abukharin/reasoning/alignment/data/val_deepscaler.json \
# env.math.num_workers=16

source /lustre/fsw/portfolios/coreai/users/zhiyul/secrets.sh

SEQUENCE_LENGTH=8192

NNODES=1
uv run ./examples/run_grpo_deepscaler_logprob_compare.py \
 cluster.num_nodes=${NNODES} \
 logger.wandb.name="zhiyul-qwen2.5-1.5b_deepscaler_${SEQUENCE_LENGTH}" \
 logger.wandb_enabled=False \
 logger.wandb.project=deepscaler_replication \
 checkpointing.checkpoint_dir="results/qwen2.5-1.5b_deepscaler_${SEQUENCE_LENGTH}" \
 policy.model_name=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B \
 policy.make_sequence_length_divisible_by=8 \
 policy.generation.vllm_cfg.tensor_parallel_size=1 \
 cluster.num_nodes=1 \
 policy.dtensor_cfg.enabled=True \
 policy.dtensor_cfg.tensor_parallel_size=1 \
 policy.dtensor_cfg.sequence_parallel=False \
 policy.dtensor_cfg.activation_checkpointing=False \
 policy.dtensor_cfg.cpu_offload=False \
 cluster.gpus_per_node=8 \
 grpo.num_prompts_per_step=128 \
 grpo.num_generations_per_prompt=8 \
 grpo.val_period=10 \
 grpo.max_val_samples=64 \
 grpo.val_batch_size=64 \
 loss_fn.reference_policy_kl_penalty=0.001 \
 loss_fn.use_on_policy_kl_approximation=False \
 loss_fn.use_importance_sampling_correction=False \
 checkpointing.keep_top_k=10 \
 checkpointing.save_period=10 \
 policy.train_global_batch_size=64 \
 policy.train_micro_batch_size=1 \
 policy.generation_batch_size=32 \
 policy.logprob_batch_size=1 \
 policy.max_total_sequence_length=${SEQUENCE_LENGTH} \
 policy.optimizer.kwargs.lr=1e-6 \
 policy.optimizer.kwargs.weight_decay=0 \
 policy.generation.temperature=1 \
 policy.generation.vllm_cfg.tensor_parallel_size=1 \
 policy.generation.vllm_cfg.gpu_memory_utilization=0.6 \
 data.dataset_name=custom \
 ++data.train_path=/lustre/fsw/portfolios/coreai/users/zhiyul/benchmark-rl/reinforcer/data/train_deepscaler.json \
 ++data.val_path=/lustre/fsw/portfolios/coreai/users/zhiyul/benchmark-rl/reinforcer/data/val_deepscaler.json \
 env.math.num_workers=16