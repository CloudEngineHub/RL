# Sample sweep configuration for GRPO math experiments
# Each parameter can have a list of values to sweep over
# The launcher will generate all possible combinations

# Required parameter that must match the target script name
script_path: "examples/run_sft.py"

# Optional: Path to the base YAML config file
# Can be overridden by the --config command-line argument
# If null and --config is not provided, no base config will be used
config_path: "examples/configs/sft_mdlm.yaml" 


# Model configuration
policy.is_mdlm: [true]
policy.model_name: ["GSAI-ML/LLaDA-8B-Base"]

# Data configuration
data.dataset_name: ["openai_format"]
data.train_data_path: ["/workspace/data/degert/train.jsonl"]
data.val_data_path: ["/workspace/data/degert/test.jsonl"]
data.chat_key: ["messages"]
data.system_key: [null]
data.system_prompt: [null]

# Training steps
sft.max_num_epochs: [100]
sft.max_num_steps: [10000]

# Resources
cluster.num_nodes: [1]
cluster.gpus_per_node: [8]

# Training configuration
policy.train_global_batch_size: [64, 128]
policy.train_micro_batch_size: [1]
policy.max_total_sequence_length: [2048, 4096]

# Learning rate
policy.optimizer.kwargs.lr: [1e-4, 1e-5, 1e-6]
