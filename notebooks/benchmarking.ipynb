{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧹 Clearing GPU memory...\n",
            "   GPU 0: 0.03GB allocated, 0.03GB cached of 79.10GB total\n",
            "   ✅ CUDA cache cleared\n",
            "   💾 System RAM: 90.76GB used of 2015.47GB total\n",
            "   🗑️  Garbage collection completed\n",
            "============================================================\n",
            "🔧 PyTorch CUDA memory management configured\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# GPU MEMORY CLEANUP - Run this first to ensure clean state\n",
        "# =============================================================================\n",
        "\n",
        "import torch\n",
        "import gc\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clear all GPU memory and run garbage collection\"\"\"\n",
        "    print(\"🧹 Clearing GPU memory...\")\n",
        "    \n",
        "    # Force garbage collection\n",
        "    gc.collect()\n",
        "    \n",
        "    # Clear CUDA cache if available\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        \n",
        "        # Get GPU memory info\n",
        "        for i in range(torch.cuda.device_count()):\n",
        "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
        "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
        "            cached = torch.cuda.memory_reserved(i) / 1024**3\n",
        "            print(f\"   GPU {i}: {allocated:.2f}GB allocated, {cached:.2f}GB cached of {gpu_memory:.2f}GB total\")\n",
        "        \n",
        "        # Clear again after getting info\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"   ✅ CUDA cache cleared\")\n",
        "    else:\n",
        "        print(\"   ⚠️  CUDA not available\")\n",
        "    \n",
        "    # Get system memory info\n",
        "    memory = psutil.virtual_memory()\n",
        "    print(f\"   💾 System RAM: {memory.used / 1024**3:.2f}GB used of {memory.total / 1024**3:.2f}GB total\")\n",
        "    \n",
        "    print(\"   🗑️  Garbage collection completed\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# Clear memory at startup\n",
        "clear_gpu_memory()\n",
        "\n",
        "# Optional: Set memory management flags\n",
        "if torch.cuda.is_available():\n",
        "    # Prevent memory fragmentation\n",
        "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "    print(\"🔧 PyTorch CUDA memory management configured\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# check if models are loaded and discard them if so\n",
        "if 'llama3_model' in globals():\n",
        "    del llama3_model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "if 'llada_model' in globals():\n",
        "    del llada_model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading tokenizers...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizers loaded. Models will be loaded on-demand to save memory.\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
        "import gc # For garbage collection\n",
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "# --- Configuration ---\n",
        "LLADA_MODEL_NAME = \"GSAI-ML/LLaDA-8B-Instruct\"\n",
        "LLAMA3_MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# --- Load Tokenizers ---\n",
        "print(\"Loading tokenizers...\")\n",
        "llada_tokenizer = AutoTokenizer.from_pretrained(LLADA_MODEL_NAME, trust_remote_code=True)\n",
        "llama3_tokenizer = AutoTokenizer.from_pretrained(LLAMA3_MODEL_NAME)\n",
        "\n",
        "# Add a padding token to Llama3 tokenizer if it doesn't exist\n",
        "if llama3_tokenizer.pad_token is None:\n",
        "    llama3_tokenizer.pad_token = llama3_tokenizer.eos_token\n",
        "# Note: The model config for pad_token_id will be set when the model is loaded.\n",
        "    \n",
        "print(f\"Tokenizers loaded. Models will be loaded on-demand to save memory.\")\n",
        "print(f\"Using device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Generation parameters configured:\n",
            "   LLaDA: 4 steps/block, 8 block length, temp=0.0\n",
            "   Llama3: temp=0.0, top_p=1.0\n",
            "   Benchmark: 3 lengths, 1 trials each\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# GENERATION PARAMETERS CONFIGURATION\n",
        "# =============================================================================\n",
        "\"\"\"\n",
        "Configure generation parameters for both models here. \n",
        "This allows easy experimentation with different settings.\n",
        "\"\"\"\n",
        "\n",
        "# --- LLaDA Generation Parameters ---\n",
        "LLADA_CONFIG = {\n",
        "    # Core diffusion parameters\n",
        "    'block_length': 8,         # Number of tokens to process in each block\n",
        "    'steps': 4,                # Number of diffusion steps per block (increased for faithful implementation)\n",
        "    'mask_id': 126336,          # Token ID for [MASK] token in LLaDA\n",
        "    \n",
        "    # Sampling strategy (for faithful diffusion)\n",
        "    'temperature': 0.0,         # Sampling temperature (0.0 = deterministic, >0.0 = stochastic)\n",
        "    'remasking': 'low_confidence', # Remasking strategy ('low_confidence' or 'random')\n",
        "    'cfg_scale': 0.0,          # Classifier-free guidance scale (0.0 = disabled for speed)\n",
        "    \n",
        "    # Legacy parameters (kept for compatibility)\n",
        "    'use_greedy': True,         # Use greedy decoding (deterministic) - mapped to temperature=0.0\n",
        "    'confidence_threshold': 0.5, # Minimum confidence for token selection\n",
        "    'top_k': 50,               # Top-k sampling (not used in faithful implementation)\n",
        "    'top_p': 0.9,              # Top-p (nucleus) sampling (not used in faithful implementation)\n",
        "}\n",
        "\n",
        "# --- Llama3/vLLM Generation Parameters ---\n",
        "LLAMA3_CONFIG = {\n",
        "    # Core generation parameters\n",
        "    'temperature': 0.0,         # 0.0 = greedy, >0.0 = sampling\n",
        "    'top_k': -1,                # Top-k sampling (-1 = disabled)\n",
        "    'top_p': 1.0,               # Top-p (nucleus) sampling (1.0 = disabled)\n",
        "    'repetition_penalty': 1.0,  # Penalty for repeating tokens\n",
        "    \n",
        "    # Advanced parameters\n",
        "    'frequency_penalty': 0.0,   # Penalty for frequent tokens\n",
        "    'presence_penalty': 0.0,    # Penalty for tokens that have appeared\n",
        "    'min_tokens': 0,           # Minimum number of tokens to generate\n",
        "    'stop_sequences': None,     # List of strings that stop generation (None = disabled)\n",
        "    \n",
        "    # vLLM specific\n",
        "    'n': 1,                    # Number of completions to generate\n",
        "    'best_of': 1,              # Number of candidates to generate and return best\n",
        "}\n",
        "\n",
        "# --- Benchmarking Parameters ---\n",
        "BENCHMARK_CONFIG = {\n",
        "    'prompt_text': \"Explain the theory of general relativity in a few paragraphs.\",\n",
        "    'generation_lengths': [512, 768, 1024],  # Token lengths to benchmark\n",
        "    'num_trials': 1,                          # Number of trials per benchmark\n",
        "    'show_generated_text': True,              # Whether to display generated text during benchmarks\n",
        "    'gpu_memory_utilization': 0.9,           # GPU memory limit for vLLM (0.0-1.0)\n",
        "}\n",
        "\n",
        "print(\"✅ Generation parameters configured:\")\n",
        "print(f\"   LLaDA: {LLADA_CONFIG['steps']} steps/block, {LLADA_CONFIG['block_length']} block length, temp={LLADA_CONFIG['temperature']}\")\n",
        "print(f\"   Llama3: temp={LLAMA3_CONFIG['temperature']}, top_p={LLAMA3_CONFIG['top_p']}\")\n",
        "print(f\"   Benchmark: {len(BENCHMARK_CONFIG['generation_lengths'])} lengths, {BENCHMARK_CONFIG['num_trials']} trials each\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Faithful LLaDA diffusion implementation loaded:\n",
            "   📦 add_gumbel_noise() - Proper Gumbel sampling\n",
            "   📦 get_num_transfer_tokens() - Linear noise schedule\n",
            "   📦 generate() - Full diffusion process\n",
            "   📦 llada_generate_faithful() - Configured wrapper\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# FAITHFUL LLaDA DIFFUSION IMPLEMENTATION\n",
        "# =============================================================================\n",
        "\"\"\"\n",
        "Faithful implementation of LLaDA diffusion language model based on generation.ipynb.\n",
        "This replaces the problematic simple generation that was producing repetitive text.\n",
        "\"\"\"\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def add_gumbel_noise(logits, temperature):\n",
        "    '''\n",
        "    The Gumbel max is a method for sampling categorical distributions.\n",
        "    According to arXiv:2409.02908, for MDM, low-precision Gumbel Max improves perplexity score but reduces generation quality.\n",
        "    Thus, we use float64.\n",
        "    '''\n",
        "    if temperature == 0:\n",
        "        return logits\n",
        "    logits = logits.to(torch.float64)\n",
        "    noise = torch.rand_like(logits, dtype=torch.float64)\n",
        "    gumbel_noise = (- torch.log(noise)) ** temperature\n",
        "    return logits.exp() / gumbel_noise\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_num_transfer_tokens(mask_index, steps):\n",
        "    '''\n",
        "    In the reverse process, the interval [0, 1] is uniformly discretized into steps intervals.\n",
        "    Furthermore, because LLaDA employs a linear noise schedule (as defined in Eq. (8)),\n",
        "    the expected number of tokens transitioned at each step should be consistent.\n",
        "\n",
        "    This function is designed to precompute the number of tokens that need to be transitioned at each step.\n",
        "    '''\n",
        "    mask_num = mask_index.sum(dim=1, keepdim=True)\n",
        "\n",
        "    base = mask_num // steps\n",
        "    remainder = mask_num % steps\n",
        "\n",
        "    num_transfer_tokens = torch.zeros(mask_num.size(0), steps, device=mask_index.device, dtype=torch.int64) + base\n",
        "\n",
        "    for i in range(mask_num.size(0)):\n",
        "        num_transfer_tokens[i, :remainder[i]] += 1\n",
        "\n",
        "    return num_transfer_tokens\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate(model, prompt, steps=128, gen_length=128, block_length=128, temperature=0.,\n",
        "             cfg_scale=0., remasking='low_confidence', mask_id=126336):\n",
        "    '''\n",
        "    Faithful LLaDA diffusion generation function.\n",
        "    \n",
        "    Args:\n",
        "        model: Mask predictor.\n",
        "        prompt: A tensor of shape (1, L).\n",
        "        steps: Sampling steps, less than or equal to gen_length.\n",
        "        gen_length: Generated answer length.\n",
        "        block_length: Block length, less than or equal to gen_length. If less than gen_length, it means using semi_autoregressive remasking.\n",
        "        temperature: Categorical distribution sampling temperature.\n",
        "        cfg_scale: Unsupervised classifier-free guidance scale.\n",
        "        remasking: Remasking strategy. 'low_confidence' or 'random'.\n",
        "        mask_id: The token id of [MASK] is 126336.\n",
        "    '''\n",
        "    x = torch.full((1, prompt.shape[1] + gen_length), mask_id, dtype=torch.long).to(model.device)\n",
        "    x[:, :prompt.shape[1]] = prompt.clone()\n",
        "\n",
        "    prompt_index = (x != mask_id)\n",
        "\n",
        "    assert gen_length % block_length == 0\n",
        "    num_blocks = gen_length // block_length\n",
        "\n",
        "    assert steps % num_blocks == 0\n",
        "    steps = steps // num_blocks\n",
        "\n",
        "    for num_block in range(num_blocks):\n",
        "        block_mask_index = (x[:, prompt.shape[1] + num_block * block_length: prompt.shape[1] + (num_block + 1) * block_length:] == mask_id)\n",
        "        num_transfer_tokens = get_num_transfer_tokens(block_mask_index, steps)\n",
        "        for i in range(steps):\n",
        "            mask_index = (x == mask_id)\n",
        "            if cfg_scale > 0.:\n",
        "                un_x = x.clone()\n",
        "                un_x[prompt_index] = mask_id\n",
        "                x_ = torch.cat([x, un_x], dim=0)\n",
        "                logits = model(x_).logits\n",
        "                logits, un_logits = torch.chunk(logits, 2, dim=0)\n",
        "                logits = un_logits + (cfg_scale + 1) * (logits - un_logits)\n",
        "            else:\n",
        "                logits = model(x).logits\n",
        "\n",
        "            logits_with_noise = add_gumbel_noise(logits, temperature=temperature)\n",
        "            x0 = torch.argmax(logits_with_noise, dim=-1) # b, l\n",
        "\n",
        "            if remasking == 'low_confidence':\n",
        "                p = F.softmax(logits, dim=-1)\n",
        "                x0_p = torch.squeeze(\n",
        "                    torch.gather(p, dim=-1, index=torch.unsqueeze(x0, -1)), -1) # b, l\n",
        "            elif remasking == 'random':\n",
        "                x0_p = torch.rand((x0.shape[0], x0.shape[1]), device=x0.device)\n",
        "            else:\n",
        "                raise NotImplementedError(remasking)\n",
        "\n",
        "            x0_p[:, prompt.shape[1] + (num_block + 1) * block_length:] = -np.inf\n",
        "\n",
        "            x0 = torch.where(mask_index, x0, x)\n",
        "            confidence = torch.where(mask_index, x0_p, -np.inf)\n",
        "\n",
        "            transfer_index = torch.zeros_like(x0, dtype=torch.bool, device=x0.device)\n",
        "            for j in range(confidence.shape[0]):\n",
        "                _, select_index = torch.topk(confidence[j], k=num_transfer_tokens[j, i])\n",
        "                transfer_index[j, select_index] = True\n",
        "            x[transfer_index] = x0[transfer_index]\n",
        "\n",
        "    return x\n",
        "\n",
        "@torch.no_grad()\n",
        "def llada_generate_faithful(model, tokenizer, prompt_text, gen_length=512, config=None):\n",
        "    \"\"\"\n",
        "    Faithful LLaDA generation function using proper diffusion process.\n",
        "    Uses LLADA_CONFIG by default, but can be overridden with custom config.\n",
        "    \n",
        "    This function replaces the problematic llada_generate_simple and implements\n",
        "    the full diffusion process for high-quality generation.\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = LLADA_CONFIG\n",
        "    \n",
        "    # Extract parameters from config\n",
        "    block_length = config.get('block_length', 128)\n",
        "    steps = config.get('steps', 4)\n",
        "    mask_id = config.get('mask_id', 126336)\n",
        "    temperature = config.get('temperature', 0.0)\n",
        "    \n",
        "    # Map config parameters to diffusion function parameters\n",
        "    # For benchmarking, we use low_confidence remasking for deterministic results\n",
        "    remasking = 'low_confidence'\n",
        "    cfg_scale = 0.0  # No CFG for speed benchmarking\n",
        "    \n",
        "    # Format prompt for instruct model\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
        "    formatted_prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
        "    input_ids = tokenizer(formatted_prompt, return_tensors=\"pt\")['input_ids'].to(DEVICE)\n",
        "    \n",
        "    # Ensure gen_length is divisible by block_length for proper diffusion\n",
        "    if gen_length % block_length != 0:\n",
        "        # Adjust gen_length to be divisible by block_length\n",
        "        gen_length = ((gen_length + block_length - 1) // block_length) * block_length\n",
        "        print(f\"  ⚠️  Adjusted gen_length to {gen_length} to be divisible by block_length ({block_length})\")\n",
        "    \n",
        "    # Generate using faithful diffusion process\n",
        "    output = generate(\n",
        "        model=model,\n",
        "        prompt=input_ids,\n",
        "        steps=steps * (gen_length // block_length),  # Total steps for all blocks\n",
        "        gen_length=gen_length,\n",
        "        block_length=block_length,\n",
        "        temperature=temperature,\n",
        "        cfg_scale=cfg_scale,\n",
        "        remasking=remasking,\n",
        "        mask_id=mask_id\n",
        "    )\n",
        "    \n",
        "    # Decode only the generated part (excluding input)\n",
        "    generated_text = tokenizer.batch_decode(output[:, input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
        "    \n",
        "    return generated_text\n",
        "\n",
        "print(\"✅ Faithful LLaDA diffusion implementation loaded:\")\n",
        "print(\"   📦 add_gumbel_noise() - Proper Gumbel sampling\")\n",
        "print(\"   📦 get_num_transfer_tokens() - Linear noise schedule\")\n",
        "print(\"   📦 generate() - Full diffusion process\")\n",
        "print(\"   📦 llada_generate_faithful() - Configured wrapper\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llama3 generation function loaded.\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def llama3_generate(model, tokenizer, prompt_text, gen_length=512):\n",
        "    \"\"\"\n",
        "    Standard autoregressive generation for Llama3.\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(DEVICE)\n",
        "    \n",
        "    # Generate text\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=gen_length,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=False  # Use greedy decoding for speed comparison\n",
        "    )\n",
        "    \n",
        "    # Decode the generated tokens\n",
        "    response = outputs[0][input_ids.shape[-1]:]\n",
        "    return tokenizer.decode(response, skip_special_tokens=True)\n",
        "\n",
        "print(\"Llama3 generation function loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vLLM generation function loaded.\n"
          ]
        }
      ],
      "source": [
        "def vllm_generate(model, tokenizer, prompt_text, gen_length=512, config=None):\n",
        "    \"\"\"\n",
        "    Generates text using the vLLM engine with configurable parameters.\n",
        "    Uses LLAMA3_CONFIG by default, but can be overridden with custom config.\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = LLAMA3_CONFIG\n",
        "    \n",
        "    # The tokenizer is used for creating the prompt, but vLLM handles tokenization internally\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
        "    prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
        "    \n",
        "    # Extract parameters with proper validation\n",
        "    temperature = config.get('temperature', 0.0)\n",
        "    top_k = config.get('top_k', -1)\n",
        "    top_p = config.get('top_p', 1.0)\n",
        "    n = config.get('n', 1)\n",
        "    best_of = config.get('best_of', 1)\n",
        "    \n",
        "    # Ensure best_of >= n (required by vLLM)\n",
        "    if best_of < n:\n",
        "        best_of = n\n",
        "    \n",
        "    # Handle stop sequences properly\n",
        "    stop_sequences = config.get('stop_sequences')\n",
        "    if stop_sequences == [] or stop_sequences is None:\n",
        "        stop_sequences = None\n",
        "    \n",
        "    # Create sampling parameters with only supported parameters\n",
        "    try:\n",
        "        sampling_params = SamplingParams(\n",
        "            n=n,\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "            repetition_penalty=config.get('repetition_penalty', 1.0),\n",
        "            frequency_penalty=config.get('frequency_penalty', 0.0),\n",
        "            presence_penalty=config.get('presence_penalty', 0.0),\n",
        "            max_tokens=gen_length,\n",
        "            min_tokens=config.get('min_tokens', 0),\n",
        "            stop=stop_sequences,\n",
        "            best_of=best_of,\n",
        "        )\n",
        "    except TypeError as e:\n",
        "        # Fallback for older vLLM versions with fewer parameters\n",
        "        print(f\"⚠️  Parameter not supported in this vLLM version, using basic parameters: {e}\")\n",
        "        sampling_params = SamplingParams(\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "            max_tokens=gen_length,\n",
        "            stop=stop_sequences,\n",
        "        )\n",
        "    \n",
        "    # Generate text\n",
        "    outputs = model.generate(prompt, sampling_params)\n",
        "    \n",
        "    # Return the generated text from the first output\n",
        "    return outputs[0].outputs[0].text\n",
        "\n",
        "print(\"vLLM generation function loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Benchmarking framework loaded.\n"
          ]
        }
      ],
      "source": [
        "# --- Benchmarking Framework ---\n",
        "# Extract parameters from BENCHMARK_CONFIG\n",
        "PROMPT_TEXT = BENCHMARK_CONFIG['prompt_text']\n",
        "GENERATION_LENGTHS = BENCHMARK_CONFIG['generation_lengths']\n",
        "NUM_TRIALS = BENCHMARK_CONFIG['num_trials']\n",
        "\n",
        "def run_benchmark(model_name, gen_function, tokenizer, gen_length, print_text=False, **kwargs):\n",
        "    \"\"\"\n",
        "    Runs the generation benchmark for a given model and returns timing statistics.\n",
        "    \"\"\"\n",
        "    total_time = 0\n",
        "    total_tokens = 0\n",
        "    generated_texts = []\n",
        "    \n",
        "    # Warm-up run\n",
        "    print(f\"  Warm-up run for {gen_length} tokens...\")\n",
        "    gen_function(\n",
        "        model=kwargs.get('model'), \n",
        "        tokenizer=tokenizer, \n",
        "        prompt_text=PROMPT_TEXT, \n",
        "        gen_length=gen_length,\n",
        "        **kwargs.get('func_args', {})\n",
        "    )\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    # Timed trials\n",
        "    for i in range(NUM_TRIALS):\n",
        "        print(f\"  Trial {i+1}/{NUM_TRIALS} for {gen_length} tokens...\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        generated_text = gen_function(\n",
        "            model=kwargs.get('model'), \n",
        "            tokenizer=tokenizer, \n",
        "            prompt_text=PROMPT_TEXT, \n",
        "            gen_length=gen_length,\n",
        "            **kwargs.get('func_args', {})\n",
        "        )\n",
        "        \n",
        "        torch.cuda.synchronize()\n",
        "        end_time = time.time()\n",
        "        \n",
        "        elapsed_time = end_time - start_time\n",
        "        num_tokens = len(tokenizer.encode(generated_text))\n",
        "        \n",
        "        total_time += elapsed_time\n",
        "        total_tokens += num_tokens\n",
        "        generated_texts.append(generated_text)\n",
        "        \n",
        "        # Print generated text if requested\n",
        "        if print_text:\n",
        "            print(f\"    📝 Generated Text (Trial {i+1}):\")\n",
        "            print(f\"    {'-' * 50}\")\n",
        "            print(f\"    {generated_text[:200]}{'...' if len(generated_text) > 200 else ''}\")\n",
        "            print(f\"    {'-' * 50}\")\n",
        "            print(f\"    Tokens: {num_tokens}, Time: {elapsed_time:.2f}s\")\n",
        "            print()\n",
        "\n",
        "    avg_time = total_time / NUM_TRIALS\n",
        "    avg_tokens = total_tokens / NUM_TRIALS\n",
        "    tokens_per_sec = avg_tokens / avg_time if avg_time > 0 else 0\n",
        "    \n",
        "    result = {\n",
        "        \"Model\": model_name,\n",
        "        \"Gen Length\": gen_length,\n",
        "        \"Avg Time (s)\": avg_time,\n",
        "        \"Avg Tokens\": avg_tokens,\n",
        "        \"Tokens/Sec\": tokens_per_sec\n",
        "    }\n",
        "    \n",
        "    # Add generated texts to result if requested\n",
        "    if print_text:\n",
        "        result[\"Generated_Texts\"] = generated_texts\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(\"Benchmarking framework loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading LLaDA model: GSAI-ML/LLaDA-8B-Instruct...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 228.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLaDA model loaded.\n",
            "\\n==================== Benchmarking LLaDA for 512 tokens ====================\n",
            "📋 Config: 4 steps/block, 8 block_length, temp=0.0\n",
            "📝 Showing generated texts for this length...\n",
            "  Warm-up run for 512 tokens...\n",
            "  Trial 1/1 for 512 tokens...\n",
            "    📝 Generated Text (Trial 1):\n",
            "    --------------------------------------------------\n",
            "    The theory of general relativity, proposed by Albert Einstein in 1915, is a framework of grav physics that describes the effects of mass and energy. It to the Newtonian theory of gravity, which pos th...\n",
            "    --------------------------------------------------\n",
            "    Tokens: 162, Time: 5.77s\n",
            "\n",
            "\\n==================== Benchmarking LLaDA for 768 tokens ====================\n",
            "📋 Config: 4 steps/block, 8 block_length, temp=0.0\n",
            "  Warm-up run for 768 tokens...\n",
            "  Trial 1/1 for 768 tokens...\n",
            "\\n==================== Benchmarking LLaDA for 1024 tokens ====================\n",
            "📋 Config: 4 steps/block, 8 block_length, temp=0.0\n",
            "  Warm-up run for 1024 tokens...\n",
            "  Trial 1/1 for 1024 tokens...\n",
            "\\nClearing LLaDA model from memory...\n",
            "LLaDA model cleared.\n"
          ]
        }
      ],
      "source": [
        "# --- Run Benchmarks ---\n",
        "results_list = []\n",
        "\n",
        "# --- LLaDA Benchmark ---\n",
        "print(f\"Loading LLaDA model: {LLADA_MODEL_NAME}...\")\n",
        "llada_model = AutoModel.from_pretrained(\n",
        "    LLADA_MODEL_NAME, \n",
        "    trust_remote_code=True, \n",
        "    torch_dtype=torch.bfloat16\n",
        ").to(DEVICE).eval()\n",
        "print(\"LLaDA model loaded.\")\n",
        "\n",
        "# Use configuration instead of hardcoded parameters\n",
        "for i, length in enumerate(GENERATION_LENGTHS):\n",
        "    print(f\"\\\\n{'='*20} Benchmarking LLaDA for {length} tokens {'='*20}\")\n",
        "    print(f\"📋 Config: {LLADA_CONFIG['steps']} steps/block, {LLADA_CONFIG['block_length']} block_length, temp={LLADA_CONFIG['temperature']}\")\n",
        "    \n",
        "    # Print text based on configuration\n",
        "    show_text = BENCHMARK_CONFIG['show_generated_text'] and (i == 0)\n",
        "    if show_text:\n",
        "        print(\"📝 Showing generated texts for this length...\")\n",
        "    \n",
        "    llada_results = run_benchmark(\n",
        "        \"LLaDA-8B\",\n",
        "        llada_generate_faithful,\n",
        "        llada_tokenizer,\n",
        "        length,\n",
        "        print_text=show_text,\n",
        "        model=llada_model,\n",
        "        func_args={'config': LLADA_CONFIG}  # Pass the entire config\n",
        "    )\n",
        "    results_list.append(llada_results)\n",
        "\n",
        "# Clear LLaDA model from memory\n",
        "print(\"\\\\nClearing LLaDA model from memory...\")\n",
        "del llada_model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"LLaDA model cleared.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nLoading Llama3 model with vLLM: meta-llama/Meta-Llama-3-8B-Instruct...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 08-13 19:18:29 [config.py:793] This model supports multiple tasks: {'embed', 'generate', 'score', 'reward', 'classify'}. Defaulting to 'generate'.\n",
            "INFO 08-13 19:18:29 [config.py:2118] Chunked prefill is enabled with max_num_batched_tokens=16384.\n",
            "INFO 08-13 19:18:34 [__init__.py:243] Automatically detected platform cuda.\n",
            "INFO 08-13 19:18:37 [core.py:438] Waiting for init message from front-end.\n",
            "INFO 08-13 19:18:37 [__init__.py:31] Available plugins for group vllm.general_plugins:\n",
            "INFO 08-13 19:18:37 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver\n",
            "INFO 08-13 19:18:37 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.\n",
            "INFO 08-13 19:18:37 [core.py:65] Initializing a V1 LLM engine (v0.9.0) with config: model='meta-llama/Meta-Llama-3-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Meta-Llama-3-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\": 3, \"custom_ops\": [\"none\"], \"splitting_ops\": [\"vllm.unified_attention\", \"vllm.unified_attention_with_output\"], \"compile_sizes\": [], \"inductor_compile_config\": {\"enable_auto_functionalized_v2\": false}, \"use_cudagraph\": true, \"cudagraph_num_of_warmups\": 1, \"cudagraph_capture_sizes\": [512, 504, 496, 488, 480, 472, 464, 456, 448, 440, 432, 424, 416, 408, 400, 392, 384, 376, 368, 360, 352, 344, 336, 328, 320, 312, 304, 296, 288, 280, 272, 264, 256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], \"max_capture_size\": 512}\n",
            "WARNING 08-13 19:18:37 [utils.py:2671] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x1553cad63200>\n",
            "INFO 08-13 19:18:37 [parallel_state.py:1064] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "WARNING 08-13 19:18:37 [topk_topp_sampler.py:58] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
            "INFO 08-13 19:18:37 [gpu_model_runner.py:1531] Starting to load model meta-llama/Meta-Llama-3-8B-Instruct...\n",
            "INFO 08-13 19:18:37 [cuda.py:217] Using Flash Attention backend on V1 engine.\n",
            "INFO 08-13 19:18:38 [backends.py:35] Using InductorAdaptor\n",
            "INFO 08-13 19:18:44 [weight_utils.py:291] Using model weights format ['*.safetensors']\n",
            "INFO 08-13 19:18:45 [weight_utils.py:307] Time spent downloading weights for meta-llama/Meta-Llama-3-8B-Instruct: 0.617722 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:00,  5.89it/s]\n",
            "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:01,  1.95it/s]\n",
            "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.53it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.39it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.56it/s]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 08-13 19:18:48 [default_loader.py:280] Loading weights took 2.66 seconds\n",
            "INFO 08-13 19:18:48 [gpu_model_runner.py:1549] Model loading took 14.9596 GiB and 10.205927 seconds\n",
            "INFO 08-13 19:18:53 [backends.py:459] Using cache directory: /root/.cache/vllm/torch_compile_cache/8943ea9d20/rank_0_0 for vLLM's torch.compile\n",
            "INFO 08-13 19:18:53 [backends.py:469] Dynamo bytecode transform time: 5.45 s\n",
            "INFO 08-13 19:18:57 [backends.py:132] Directly load the compiled graph(s) for shape None from the cache, took 3.794 s\n",
            "INFO 08-13 19:18:58 [monitor.py:33] torch.compile takes 5.45 s in total\n",
            "INFO 08-13 19:18:59 [kv_cache_utils.py:637] GPU KV cache size: 409,744 tokens\n",
            "INFO 08-13 19:18:59 [kv_cache_utils.py:640] Maximum concurrency for 8,192 tokens per request: 50.02x\n",
            "INFO 08-13 19:19:14 [gpu_model_runner.py:1933] Graph capturing finished in 16 secs, took 0.65 GiB\n",
            "INFO 08-13 19:19:14 [core.py:167] init engine (profile, create kv cache, warmup model) took 26.60 seconds\n",
            "Llama3 vLLM model loaded.\n",
            "\\n==================== Benchmarking Llama3 (vLLM) for 512 tokens ====================\n",
            "📋 Config: temp=0.0, top_p=1.0, rep_penalty=1.0\n",
            "📝 Showing generated texts for this length...\n",
            "  Warm-up run for 512 tokens...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 1646.76it/s]\n",
            "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.52s/it, est. speed input: 9.53 toks/s, output: 141.34 toks/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Trial 1/1 for 512 tokens...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 1893.59it/s]\n",
            "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it, est. speed input: 9.55 toks/s, output: 142.06 toks/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    📝 Generated Text (Trial 1):\n",
            "    --------------------------------------------------\n",
            "    The theory of general relativity, proposed by Albert Einstein in 1915, is a fundamental concept in modern physics that revolutionized our understanding of space, time, and gravity. In a nutshell, gene...\n",
            "    --------------------------------------------------\n",
            "    Tokens: 357, Time: 2.52s\n",
            "\n",
            "\\n==================== Benchmarking Llama3 (vLLM) for 768 tokens ====================\n",
            "📋 Config: temp=0.0, top_p=1.0, rep_penalty=1.0\n",
            "  Warm-up run for 768 tokens...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 1964.55it/s]\n",
            "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it, est. speed input: 9.55 toks/s, output: 142.08 toks/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Trial 1/1 for 768 tokens...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 1818.08it/s]\n",
            "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it, est. speed input: 9.55 toks/s, output: 142.07 toks/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n==================== Benchmarking Llama3 (vLLM) for 1024 tokens ====================\n",
            "📋 Config: temp=0.0, top_p=1.0, rep_penalty=1.0\n",
            "  Warm-up run for 1024 tokens...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 2001.10it/s]\n",
            "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it, est. speed input: 9.55 toks/s, output: 142.09 toks/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Trial 1/1 for 1024 tokens...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 1805.55it/s]\n",
            "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it, est. speed input: 9.55 toks/s, output: 142.10 toks/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nClearing Llama3 model from memory...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[rank0]:[W813 19:19:31.245135030 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llama3 model cleared.\n",
            "\\nBenchmark Complete!\n"
          ]
        }
      ],
      "source": [
        "# --- Llama3 vLLM Benchmark ---\n",
        "print(f\"\\\\nLoading Llama3 model with vLLM: {LLAMA3_MODEL_NAME}...\")\n",
        "# vLLM handles device placement automatically\n",
        "# Use GPU memory utilization from config\n",
        "llama3_model = LLM(\n",
        "    model=LLAMA3_MODEL_NAME, \n",
        "    trust_remote_code=True,\n",
        "    gpu_memory_utilization=BENCHMARK_CONFIG['gpu_memory_utilization']\n",
        ")\n",
        "print(\"Llama3 vLLM model loaded.\")\n",
        "\n",
        "for i, length in enumerate(GENERATION_LENGTHS):\n",
        "    print(f\"\\\\n{'='*20} Benchmarking Llama3 (vLLM) for {length} tokens {'='*20}\")\n",
        "    print(f\"📋 Config: temp={LLAMA3_CONFIG['temperature']}, top_p={LLAMA3_CONFIG['top_p']}, rep_penalty={LLAMA3_CONFIG['repetition_penalty']}\")\n",
        "    \n",
        "    # Print text based on configuration\n",
        "    show_text = BENCHMARK_CONFIG['show_generated_text'] and (i == 0)\n",
        "    if show_text:\n",
        "        print(\"📝 Showing generated texts for this length...\")\n",
        "    \n",
        "    llama3_results = run_benchmark(\n",
        "        \"Llama-3-8B (vLLM)\",\n",
        "        vllm_generate,\n",
        "        llama3_tokenizer,\n",
        "        length,\n",
        "        print_text=show_text,\n",
        "        model=llama3_model,\n",
        "        func_args={'config': LLAMA3_CONFIG}  # Pass the entire config\n",
        "    )\n",
        "    results_list.append(llama3_results)\n",
        "\n",
        "# Clear Llama3 model from memory\n",
        "print(\"\\\\nClearing Llama3 model from memory...\")\n",
        "del llama3_model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Llama3 model cleared.\")\n",
        "\n",
        "# Convert results to a DataFrame for easy analysis\n",
        "results_df = pd.DataFrame(results_list)\n",
        "\n",
        "print(\"\\\\nBenchmark Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Gen Length</th>\n",
              "      <th>Avg Time (s)</th>\n",
              "      <th>Avg Tokens</th>\n",
              "      <th>Tokens/Sec</th>\n",
              "      <th>Generated_Texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LLaDA-8B</td>\n",
              "      <td>512</td>\n",
              "      <td>5.770715</td>\n",
              "      <td>162.0</td>\n",
              "      <td>28.072778</td>\n",
              "      <td>[The theory of general relativity, proposed by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LLaDA-8B</td>\n",
              "      <td>768</td>\n",
              "      <td>11.481593</td>\n",
              "      <td>199.0</td>\n",
              "      <td>17.332090</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LLaDA-8B</td>\n",
              "      <td>1024</td>\n",
              "      <td>20.115563</td>\n",
              "      <td>152.0</td>\n",
              "      <td>7.556338</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Llama-3-8B (vLLM)</td>\n",
              "      <td>512</td>\n",
              "      <td>2.516245</td>\n",
              "      <td>357.0</td>\n",
              "      <td>141.878096</td>\n",
              "      <td>[The theory of general relativity, proposed by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Llama-3-8B (vLLM)</td>\n",
              "      <td>768</td>\n",
              "      <td>2.516191</td>\n",
              "      <td>357.0</td>\n",
              "      <td>141.881148</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Llama-3-8B (vLLM)</td>\n",
              "      <td>1024</td>\n",
              "      <td>2.515387</td>\n",
              "      <td>357.0</td>\n",
              "      <td>141.926468</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Model  Gen Length  Avg Time (s)  Avg Tokens  Tokens/Sec  \\\n",
              "0           LLaDA-8B         512      5.770715       162.0   28.072778   \n",
              "1           LLaDA-8B         768     11.481593       199.0   17.332090   \n",
              "2           LLaDA-8B        1024     20.115563       152.0    7.556338   \n",
              "3  Llama-3-8B (vLLM)         512      2.516245       357.0  141.878096   \n",
              "4  Llama-3-8B (vLLM)         768      2.516191       357.0  141.881148   \n",
              "5  Llama-3-8B (vLLM)        1024      2.515387       357.0  141.926468   \n",
              "\n",
              "                                     Generated_Texts  \n",
              "0  [The theory of general relativity, proposed by...  \n",
              "1                                                NaN  \n",
              "2                                                NaN  \n",
              "3  [The theory of general relativity, proposed by...  \n",
              "4                                                NaN  \n",
              "5                                                NaN  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- Visualize Results ---\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "# Plotting the data\n",
        "pivot_df = results_df.pivot(index='Gen Length', columns='Model', values='Tokens/Sec')\n",
        "pivot_df.plot(kind='bar', ax=ax, width=0.4)\n",
        "\n",
        "# Formatting the plot\n",
        "ax.set_title('LLaDA-8B vs. Llama-3-8B Generation Speed', fontsize=16)\n",
        "ax.set_xlabel('Generation Length (Number of Tokens)', fontsize=12)\n",
        "ax.set_ylabel('Tokens per Second', fontsize=12)\n",
        "ax.tick_params(axis='x', rotation=0)\n",
        "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "ax.legend(title='Model')\n",
        "\n",
        "# Adding labels on top of the bars\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.2f', label_type='edge', fontsize=10, padding=3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "SLURM Job Kernel (root)",
      "language": "python",
      "name": "slurm-job-kernel-mfathi"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
